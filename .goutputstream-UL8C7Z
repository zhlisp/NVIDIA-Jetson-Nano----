# 2019-6-1

# 系统初始化，操作方式，点右键是粘贴复制的文本内容，左键选中文本按ctrl+c复制文本

# 输入用户名
# 输入密码2次

# Linux设置初始root密码
# 第一步：
sudo passwd root
# 第二步：[sudo] password for you: ---> 输入你的密码（你现在这个用户的密码）
# 第三步：Enter new UNIX password: ---> 设置root 密码
# 第四步：Retype new UNIX password: ---> 重复密码
# 第五步：完成

# 进和apt源地址更新为阿里源
cd /etc/apt
# 备份系统原来的文件
sudo mv sources.list sources.list_bak
# 新建命令脚本文件，用于自动区配源地址
sudo vim apt.sh

# 按a输入模式
Codename=$( (lsb_release -a)|awk '{print $2}'|tail -n 1 )
echo "\
deb http://mirrors.aliyun.com/ubuntu/ $Codename main multiverse restricted universe
deb http://mirrors.aliyun.com/ubuntu/ $Codename-backports main multiverse restricted universe
deb http://mirrors.aliyun.com/ubuntu/ $Codename-proposed main multiverse restricted universe
deb http://mirrors.aliyun.com/ubuntu/ $Codename-security main multiverse restricted universe
deb http://mirrors.aliyun.com/ubuntu/ $Codename-updates main multiverse restricted universe
deb-src http://mirrors.aliyun.com/ubuntu/ $Codename main multiverse restricted universe
deb-src http://mirrors.aliyun.com/ubuntu/ $Codename-backports main multiverse restricted universe
deb-src http://mirrors.aliyun.com/ubuntu/ $Codename-proposed main multiverse restricted universe
deb-src http://mirrors.aliyun.com/ubuntu/ $Codename-security main multiverse restricted universe
deb-src http://mirrors.aliyun.com/ubuntu/ $Codename-updates main multiverse restricted universe ">sources.list
apt update
# 按esc命令模式，输入:wq保存退出

# 添加文件执行权限
sudo chmod 777 apt.sh
# 执行更新脚本
sudo ./apt.sh

# 将所有软件升级到新版本。提示输入Y
sudo apt upgrade
# 将系统升级到新版本。提示输入Y
sudo apt dist-upgrade
# 这个命令会把安装的软件的备份也删除，但是这样不会影响软件的使用。
sudo apt clean
# 定期运行这个命令来清除那些已卸载的软件包的.deb文档。
sudo apt autoclean

# 系统初始化，更改源完成，回到用户目录
cd ~


生成指定大小的空文件
dd if=/dev/zero of=tmp.5G bs=1G count=5


# 安装gcc9.1.0前先按装些编译依赖软件，提示输入Y
sudo apt install gcc
sudo apt install make
sudo apt install make-guile
sudo apt install g++



# 开始安装
# 参考https://www.jianshu.com/p/89702b13bc51
# linux升级gcc到gcc-8.1.0
# 作者：王侦 
# 2018.07.04 07:45* 字数 58 阅读 190评论 0喜欢 0
# 1.编写升级脚步
# 切换为root用户
su 
# 切换目录
cd /usr/src
# 创建并编写脚本文件
vim upgradeGcc.sh
# 内文如下，按a输入模式
#!/bin/bash

#获取源码
#sudo wget https://mirrors.ustc.edu.cn/gnu/gcc/gcc-9.1.0/gcc-9.1.0.tar.gz
wget https://mirrors.ustc.edu.cn/gnu/gcc/gcc-9.1.0/gcc-9.1.0.tar.gz
 
#解压
#sudo tar -xvf gcc-9.1.0.tar.gz
tar -xvf gcc-9.1.0.tar.gz
 
# 进入源码目录
cd gcc-9.1.0
# 下载些组件
#sudo ./contrib/download_prerequisites
./contrib/download_prerequisites
# 返回上一层目录
cd ..
 
#建立编译输出目录
#sudo mkdir gcc-build-9.1.0
mkdir gcc-build-9.1.0
 
#进入下面目录，执行命令，生成Makefile文件
cd gcc-build-9.1.0
#sudo ../gcc-9.1.0/configure --enable-checking=release --enable-languages=c,c++ --disable-multilib
../gcc-9.1.0/configure --enable-checking=release --enable-languages=c,c++ --disable-multilib
 
#执行命令进行编译，此处利用4个job，需编译时约40分钟，此值不宜设置过高
#sudo make -j8
make -j8
 
#安装
#sudo make install
make install

# 2.执行脚步
chmod 777 upgradeGcc.sh
./upgradeGcc.sh
# 3.检测版本
gcc -v
# 4.头文件在哪
/usr/local/include/c++/9.1.0
# gcc-9.1.0安装完成
# 存在首次安装GCC不彻底污染问题，清理后继续重新编译安装
make distclean




# 以下步骤如果达到GLIBCXX_3.4.25可跳过
# 老版本在：
# /usr/include/c++/5/
# 5.编译程序并执行
# 发现以下错误
# ./test: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.22' not found (required by ./test)
# 查看当前的GLIBC版本
strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX
# //最新只到了22
# GLIBCXX_3.4.19
# GLIBCXX_3.4.20
# GLIBCXX_3.4.21
# 下载libstdc++.so.6
# 找到lib64stdc++6_9.1.0-1_i386.deb
# http://ftp.de.debian.org/debian/pool/main/g/gcc-9/
sudo wget http://ftp.de.debian.org/debian/pool/main/g/gcc-9/lib64stdc++6_9.1.0-1_i386.deb
sudo ar -x lib64stdc++6_9.1.0-1_i386.deb
sudo tar xvJf data.tar.xz
cd ./usr/lib64/
sudo mv libstdc++.so.6.0.26 /usr/lib/x86_64-linux-gnu/
cd /usr/lib/x86_64-linux-gnu/
# sudo rm libstdc++.so.6
sudo mv libstdc++.so.6 libstdc++.so.6.bak
sudo ln libstdc++.so.6.0.26 libstdc++.so.6
# 补充安装，条件合适可不装




# 安装chez-scheme
cd ~
wget https://codeload.github.com/cisco/ChezScheme/zip/master
mv master chez-scheme.zip

# 安装依赖
sudo apt install unzip
sudo apt install zip
sudo apt install uuid-dev
sudo apt install libncurses5-dev
sudo apt install libx11-dev

# 开始安装
unzip chez-scheme.zip
cd ChezScheme-master/
sudo ./configure
sudo make -j 8
sudo make install
# 安装chez-scheme完成回到用户目录
cd ~





# 安装common-lisp开发环境
sudo apt install sbcl
sudo apt install emacs
sudo apt install slime
sudo apt install cl-quicklisp
sudo apt install cl-mcclim
# 安装common-lisp开发环境完成







# nano开机设置，语言设置，输入法设置，系统升级，打开商店删不用的软件。
# 删纸牌游戏，Amazon,Fcitx等

# Linux设置初始root密码
# 第一步：
sudo passwd root
# 第二步：[sudo] password for you: ---> 输入你的密码（你现在这个用户的密码）
# 第三步：Enter new UNIX password: ---> 设置root 密码
# 第四步：Retype new UNIX password: ---> 重复密码
# 第五步：完成
@ 可选解锁root账户 
@ sudo passwd –unlock root

# Ubuntu系统无法识别exFat或FAT32的U盘
sudo apt install exfat-fuse

# 修改hosts文件
# 由于是本地编译安装，使用到了git clone命令，正常情况下，速度慢的可怜，在没有梯子的情况下，
# 只能修改下hosts文件来自我安慰了，相比原来，速度也是提升了不少，此处留下了激动的泪水。废话少说，干！
# （1）找到本地的hosts文件，并打开，
sudo vim /etc/hosts
# （2）在文件的末尾添加以下内容，顺便将 ports.ubuntu.com也添加了,
192.30.255.112 https://github.com
192.30.255.113 https://github.com
151.101.76.249 github.global.ssl.fastly.net
91.189.88.151 ports.ubuntu.com
91.189.88.150 ports.ubuntu.com
# 重启网络，生效修改后的hosts文件，
sudo /etc/init.d/networking restart

# 更新下
sudo apt update
# 将所有软件升级到新版本。提示输入Y
sudo apt upgrade
# 将系统升级到新版本。提示输入Y
sudo apt dist-upgrade
sudo apt install apt-utils

# 安装PIP和PIP3
sudo apt install python-pip
sudo apt install python3-pip

# 用pip更新Python包的三种方法（基于Python3.6.*）
# 一、pip版本的查看及更新
# 版本查看
pip -V 或 pip show pip
# pip更新
pip install --upgrade pip --user或 python -m pip install --upgrade pip --user

# pip升级后Import Error:cannot import name main解决方案
# 方法一：
sudo gedit /usr/bin/pip
sudo gedit /usr/bin/pip3
# 将原来的

from pip import main
# 改为

from pip._internal import main

# 方法二：
sudo gedit /usr/bin/pip
sudo gedit /usr/bin/pip3
# 将原来的：

from pip import main
if __name__ == '__main__':
    sys.exit(main())
# 改为：

from pip import __main__
if __name__ == '__main__':
    sys.exit(__main__._main())
# 就可以了，注意__main__左右的下划线是两个下划线，很多同学不成功的原因是因为只写了一个下划线

# 二、pip更新已安装包
# 查看有待更新的包,按需要进行更新
 #查看更新
 pip list --outdated
 #更新某个包
 pip install --upgrade <packages-name>

# 添加环境变量
sudo gedit ~/.bashrc
export PATH=/home/love/.local/bin:$PATH
source ~/.bashrc

# 安装更新工具pip-review
pip install pip-review --user
pip3 install pip-review --user


# 下面语句逐个弹出是否确认某个库需要更新
pip-review --local --interactive 

# 写Python脚本程序自动更新
import pip
from subprocess import call
from pip._internal.utils.misc import get_installed_distributions

for dist in get_installed_distributions():
    call("pip install --upgrade " + dist.project_name, shell=True)


# 这个命令会把安装的软件的备份也删除，但是这样不会影响软件的使用。
# sudo apt clean
# 定期运行这个命令来清除那些已卸载的软件包的.deb文档。
# sudo apt autoclean
# 清理不用软件，建议不懂不要清
# sudo apt autoremove


# 安装输入法
sudo apt install ibus ibus-table-wubi ibus-pinyin
# 用商店安装图形化编程
Scratch
# 安装虚拟键盘
sudo apt install onboard

# 安装录音软件
sudo apt install audacity

# 安装摄像头驱动
sudo apt install cheese
sudo apt install camorama

sudo cp /etc/apt/sources.list /etc/apt/sources.list_bak

@ 这是树莓派的阿里源
deb http://mirrors.aliyun.com/raspbian/raspbian/ jessie main contrib non-free rpi
deb-src http://mirrors.aliyun.com/raspbian/raspbian/ jessie main contrib non-free rpi
@

ubuntu 安装brew
安装
sudo apt install linuxbrew-wrapper
检查安装：brew help
brew search  #搜索包
brew install  #安装包
brew uninstall  #删除包
brew list  #列出 pkg 的文件
brew info  #关于 pkg 的信息
brew update  #更新包
brew upgrade  #升级包

安装远程桌面环境
sudo apt install xrdp

开启远程root权限
sudo vim /etc/ssh/sshd_config
#PermitRootLogin prohibit-password
PermitRootLogin yes

# 更改文件属主 -R为递归参数，应用于子文件夹和子文件，:左边的用户组可省略
sudo chown -R love:love git/
# 更改文件权限 -R为递归参数，应用于子文件夹和子文件
chmod -R git/
# 系统初始化完成





使用git clone命令从仓库下载代码，如图所示，代码下载到了本地：
git clone 链接地址.git
如果仓库代码又了更新，这时可以使用git pull命令将更新下载到本地
在对本地代码就行修改后，可以首先执行git status查看修改了哪些代码


# 安装gpu使用率显示工具
sudo apt install python3-matplotlib
git clone https://github.com/jetsonhacks/gpuGraphTX.git
cd gpuGraphTX
./gpuGraph.py
或者
python3 gpuGraph.py

下载源码

mkdir gcc; cd gcc
git init
# 默认拔出所有头（trunk，release branches，git-only branches，其他几个SVN分支）
git remote add origin git://gcc.gnu.org/git/gcc.git
# 还包括所有其他SVN分支（增加约0.2GB）
git config --add remote.origin.fetch 'refs/remotes/*:refs/remotes/svn/*'
git fetch
git checkout -b trunk svn/trunk


# 开始安装
# 1.编写升级脚步
# 切换为root用户
su 
# 切换目录
cd ~/
# 创建并编写脚本文件
vim upgradeGcc.sh
# 内文如下，按a输入模式
#!/bin/bash
# 进入源码目录
cd gcc
# 下载些组件
#sudo ./contrib/download_prerequisites
./contrib/download_prerequisites
# 返回上一层目录
cd ..
 
#建立编译输出目录
#sudo mkdir gcc-build
mkdir gcc-build
 
#进入下面目录，执行命令，生成Makefile文件
cd gcc-build
#sudo ../gcc/configure --enable-checking=release --enable-languages=c,c++ --disable-multilib
../gcc/configure --enable-checking=release --enable-languages=c,c++ --disable-multilib
 
#执行命令进行编译，此处利用4个job，需编译时约40分钟，此值不宜设置过高
#sudo make -j 4
make -j 4
 
#安装
#sudo make install
make install

@ 2.执行脚步
chmod 777 upgradeGcc.sh
./upgradeGcc.sh
# 3.检测版本
gcc -v
# 4.头文件在哪
/usr/local/include/c++/9.1.0
# gcc-9.1.0安装完成
# 存在首次安装GCC不彻底污染问题，清理后继续重新编译安装
make distclean
@

# 安装common-lisp开发环境
sudo apt install sbcl
sudo apt install clisp


sudo apt install emacs
emacs -nw  命令行方式启动
源码安装emacs
需要软件makeinfo 安装
sudo apt install texinfo
sudo apt install libgtk2.0-dev
sudo apt install libjpeg-dev
sudo apt install libxpm-dev   
sudo apt install libgif-dev  
sudo apt install libtiff5-dev
sudo apt install libiberty-dev
sudo apt install libncurses5-dev 
sudo apt install libhogweed4 --reinstall
sudo apt install libgmp-dev
sudo apt install libmpfr-dev
sudo apt install openssl
sudo apt install libssl-dev
sudo apt install build-essential
# sudo apt install gnome-core-devel
sudo apt install pkg-config
sudo apt install devhelp
# sudo apt install libglib2.0-doc libgtk2.0-doc
sudo apt install glade libglade2-dev
# sudo apt install glade-gnome glade-common glade-doc
sudo apt install libgtk2.0*
sudo apt install mailutils
sudo apt install libp11-kit-dev
sudo apt install libcurl4-gnutls-dev libcurl4-doc libgnutls28-dev libidn11-dev libkrb5-dev libldap2-dev librtmp-dev libssh2-1-dev
sudo apt install doc-base krb5-doc libgcrypt20-doc gnutls-doc gnutls-bin krb5-user

# 开始安装
sudo ./configure
sudo make -j 4
sudo make install

sbcl
git clone https://git.code.sf.net/p/sbcl/sbcl
git clone git://git.code.sf.net/p/sbcl/sbcl.git
sudo apt install texlive
cd sbcl
sudo ./make.sh
cd doc/manual && sudo make -j4
# cd tests && sh ./run-tests.sh
sudo ./install.sh


cd ~/
wget https://beta.quicklisp.org/quicklisp.lisp
sbcl
(load "quicklisp.lisp")
(quicklisp-quickstart:install)
(ql:system-apropos "vecto")
(ql:quickload "vecto")
(ql:add-to-init-file)
(quit)
升级
(ql:update-client)
(ql:update-dist "quicklisp")

(ql:quickload "quicklisp-slime-helper")

新建文件并添加下面的内容 
vim ~/.emacs

(load (expand-file-name "~/quicklisp/slime-helper.el"))
  ;; Replace "sbcl" with the path to your implementation
(setq inferior-lisp-program "sbcl")

(slime)


(ql:quickload "mcclim")
提示安装成功
测试
(asdf:oos 'asdf:load-op :clim-examples)
(in-package :clim-demo)
(demodemo)
成功显示示例

安装文本处理正则表达式
(ql:quickload :cl-ppcre)
测试功能
(asdf:oos 'asdf:test-op :cl-ppcre)




# 需要4G swap扩一下内存
git clone https://github.com/JetsonHacksNano/installSwapfile.git
cd installSwapfile/
sudo ./installSwapfile.sh -s 4


# 源码安装xz
git clone https://git.tukaani.org/xz.git
cd xz
./autogen.sh 
./configure
make -j 4
sudo make install

tar -zxvf xz-5.2.4.tar.gz
cd xz-5.2.4/
sudo ./configure
sudo make -j 4
sudo make install

玩转Jetson Nano（二）检查已安装组件
 3. 检查已经安装的系统组件
Jetson-nano的OS镜像已经自带了JetPack，cuda，cudnn，opencv等都已经安装好，并有例子，这些例子安装路径如下所示

TensorRT	/usr/src/tensorrt/samples/
CUDA	/usr/local/cuda-/samples/
cuDNN	/usr/src/cudnn_samples_v7/
Multimedia API	/usr/src/tegra_multimedia_api/
VisionWorks	/usr/share/visionworks/sources/samples/ /usr/share/visionworks-tracking/sources/samples/ /usr/share/visionworks-sfm/sources/samples/
OpenCV	/usr/share/OpenCV/samples

# 检查CUDA
Jetson-nano中已经安装了CUDA10.0版本，但是此时你如果运行 nvcc -V是不会成功的，需要你把CUDA的路径写入环境变量中。OS中自带Vim工具 ，所以运行下面的命令编辑环境变量
sudo vim  ~/.bashrc
# 在最后添加
export CUBA_HOME=/usr/local/cuda-10.0
export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH
export PATH=/usr/local/cuda-10.0/bin:$PATH
# 对了最后别忘了source一下这个文件。
source ~/.bashrc
# 进入root用户下也重复下上面的添加
# 检查OpenCV如果OpenCv安装就绪，会显示版本号
pkg-config opencv --modversion
# 检查cuDNN
cd /usr/src/cudnn_samples_v7/mnistCUDNN   #进入例子目录
sudo make     #编译一下例子
sudo chmod a+x mnistCUDNN # 为可执行文件添加执行权限
./mnistCUDNN # 执行
# 如果成功，如下所示
# Result of classification: 1 3 5
# Test passed!
# 





玩转Jetson Nano（三）安装TensorFlow GPU
用文件批量安装
sudo ./Install-tensorflow.sh

手动安装
今天的目标是安装TensorFlow GPU版本，安装TensorFlow GPU版本需要成功配置好CUDA，没有配制好的请移步上一篇博文。不过在安装TensorFlow GPU之前，有一些机器学习必须用到的安装包也需要来安装一下。

1. 安装pip
因为Jetson Nano中已经安装了Python3.6版本，所以安装pip还是比较简单的

sudo apt install python3-pip python3-dev
安装后pip是9.01版本，需要把它升级到最新版，升级后pip版本为19.0.3。这里面升级后会有一个小Bug，需要手动改一下

python3 -m pip install --upgrade pip  #升级pip
sudo vim /usr/bin/pip3   #打开pip3文件
将原来的

from pip import main
if __name__ == '__main__':
    sys.exit(main())
改成

from pip import __main__
if __name__ == '__main__':
    sys.exit(__main__._main())

修改结束后保存。运行pip3 -V成功后显示
beckhans@Jetson:~$ pip3 -V
pip 19.0.3 from /home/beckhans/.local/lib/python3.6/site-packages/pip (python 3.6)
2. 安装那些机器学习领域如雷贯耳的包
sudo apt install python3-numpy   #不知道numpy是干啥的？机器学习这个领域不适合你
sudo apt install python3-scipy
sudo apt install python3-pandas
sudo apt install python3-matplotlib
sudo apt install python3-sklearn
3. 安装TensorFlow GPU版
 （1）确认CUDA已经被正常安装
如果不能正确调用，参考这里重新安装下https://www.cnblogs.com/pertor/p/8733010.html
nvcc -V
如果能看到CUDA版本号，即为正确安装
解决sudo下nvcc找不到问题
2019年01月22日 10:00:11 square_Tsou 阅读数：127
 版权声明：随意取用(´･ω･`) / https://blog.csdn.net/square_zou/article/details/86589688
若非sudo下可以找到nvcc，而sudo下找不到
则解决方法为建立软链接

先寻找nvcc位置

which nvcc

得到路径后，建立软链接

sudo ln -s /usr/local/cuda-10.0/bin/nvcc /sbin/nvcc   #path是上一步得到的位置

重新查询

sudo nvcc -V

即可输出nvcc版本号
（2）安装所需要的包

sudo apt install python3-pip libhdf5-serial-dev hdf5-tools
（3）安装TensorFlow GPU版本 

pip3 install launchpadlib --user

pip3 install --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v42/ tensorflow-gpu==1.14+nv19.7 --user --no-warn-script-location
参考
pip3 install tensorflow-gpu --user

先安装testresource库
4. 安装Keras
既然有了TensorFlow，那就把Keras也安装上。我自己很喜欢keras，让TensorFlow变得更加简单

pip3 install keras --user
安装完成后，进入python3，检查一下安装成果，import keras时，下方提示using TensorFlow backend,就证明Keras安装成功并使用TensorFlow作为backend。

升级numpy版本到最新用来解决ModuleNotFoundError: No module named 'numpy.core._multiarray_umath' 错误（20190201）
pip3 install --user --upgrade numpy   #将numpy更新到最新版本

beckhans@Jetson:~$ python3
Python 3.6.7 (default, Oct 22 2018, 11:32:17) 
[GCC 8.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import keras
Using TensorFlow backend.
>>> 


5. 测试TensorFlow 
跑一段自己写的非线性回归代码，速度还是挺快的

vim tensorflow.py
# 写入下面的代码

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
 
x_data = np.linspace(-0.5, 0.5, 200)[:, np.newaxis]
noise = np.random.normal(0, 0.02, x_data.shape)
y_data = np.square(x_data) + noise
 
x = tf.placeholder(tf.float32, [None, 1])
y = tf.placeholder(tf.float32, [None, 1])
 
# 输入层一个神经元，输出层一个神经元，中间10个
# 第一层
Weights_L1 = tf.Variable(tf.random.normal([1, 10]))
Biases_L1 = tf.Variable(tf.zeros([1, 10]))
Wx_plus_b_L1 = tf.matmul(x, Weights_L1) + Biases_L1
L1 = tf.nn.tanh(Wx_plus_b_L1)
 
# 第二层
Weights_L2 = tf.Variable(tf.random.normal([10, 1]))
Biases_L2 = tf.Variable(tf.zeros([1, 1]))
Wx_plus_b_L2 = tf.matmul(L1, Weights_L2) + Biases_L2
pred = tf.nn.tanh(Wx_plus_b_L2)
 
# 损失函数
loss = tf.reduce_mean(tf.square(y - pred))
 
# 训练
train = tf.train.GradientDescentOptimizer(0.1).minimize(loss)
 
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(2000):
        sess.run(train, feed_dict={x: x_data, y: y_data})
        print("第{0}次，loss = {1}".format(i, sess.run(loss,feed_dict={x: x_data, y: y_data})))
    pred_vaule = sess.run(pred, feed_dict={x: x_data})
    plt.figure()
    plt.scatter(x_data, y_data)
    plt.plot(x_data, pred_vaule, 'r-', lw=5)
    plt.show()

# 执行代码

pip install tf_nightly

python3 tensorflow.py



# 不能用外网的方法
版主 您的这里也提供一个不能科学上网的办法，就是编辑CMakePrebuild.sh。把里面带有从 nvidia.app.box.com里下载东西的都注释掉。然后去我的网盘下载，并拷贝到data/networks目录。网盘链接分享下好吗
# https://pan.baidu.com/s/16rFmIRMzvcrskiaPonnOtQ 提取码：rtr4





玩转Jetson Nano（四）跑通jetson-inference
（二）下载和编译

剩下的过程就比较简单了。首先如果您没有安装git和cmake，先安装它们
apt-cache search glew
sudo apt install git cmake
sudo apt-get install fonts-glewlwyd glew-utils glewlwyd glewlwyd-common libglew-dev libglew2.0 libglewmx1.13
接着从git上克隆jetson-inference repo

git clone https://github.com/dusty-nv/jetson-inference
cd jetson-inference
git submodule update --init
配置cmake，如果您科学上网没问题的话，会自动下载许多模型。

mkdir build    #创建build文件夹
cd build       #进入build

复制网上下载的文件到build和jetson-inference/data/networks文件夹里

cmake ../      #运行cmake，它会自动执行上一级目录下面的 CMakePrebuild.sh
下载选项选否，其它按回车就好，警告不用管，不报错停止就行

cmake成功后，就需要编译了			
make -j 4
sudo make install
如果编译成功，会生成下列文件夹结构

|-build
   \aarch64		    (64-bit)
      \bin			where the sample binaries are built to
      \include		where the headers reside
      \lib			where the libraries are build to
   \armhf           (32-bit)
      \bin			where the sample binaries are built to
      \include		where the headers reside
      \lib			where the libraries are build to
（三）测试

进入测试文件夹，运行

cd jetson-inference/build/aarch64/bin
./imagenet-console orange_0.jpg output_0.jpg
imagenet-console
  args (3):  0 [./imagenet-console]  1 [orange_0.jpg]  2 [output_0.jpg]  
.........
..........
class 0950 - 0.978909  (orange)
class 0951 - 0.020962  (lemon)
imagenet-console:  'orange_0.jpg' -> 97.89090% class #950 (orange)
loaded image  fontmapA.png  (256 x 512)  2097152 bytes
[cuda]  cudaAllocMapped 2097152 bytes, CPU 0x1048a0000 GPU 0x1048a0000
[cuda]  cudaAllocMapped 8192 bytes, CPU 0x100f62000 GPU 0x100f62000
imagenet-console:  attempting to save output image to 'output_0.jpg'
imagenet-console:  completed saving 'output_0.jpg'

测试人脸
./detectnet-console peds-001.jpg output.jpg facenet



玩转Jetson Nano（五）跑通yolov3
yoloV3也是一个物品检测的小程序，而且搭建起来比较简单。这里要申明，本文用的是yoloV3的tiny版，正式版和tiny版安装的方法都是一样的，只是运行时的配置文件和权重文件不一样。我曾经试图跑正式版，但是跑不起来，基本上到第二次卷积就挂掉了，毕竟nano只有4G内存。

闲话少说，开始安装。

1. 安装CUDA，OpenCV，cuDNN

不说了，如果没安装的请看前文吧。

2. 下载

git clone https://github.com/pjreddie/darknet.git
3. 配置

cd darknet
vim Makefile   #修改Makefile
4.  将Makefile的前三行修改一下

GPU=1
CUDNN=1
OPENCV=1
5.  编译

make -j4


6. 下载权重文件，这里直接下载tiny版的权重文件

wget https://pjreddie.com/media/files/yolov3-tiny.weights
 7.  测试

./darknet detect cfg/yolov3-tiny.cfg yolov3-tiny.weights data/dog.jpg
layer     filters    size              input                output
    0 conv     16  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  16  0.150 BFLOPs
    1 max          2 x 2 / 2   416 x 416 x  16   ->   208 x 208 x  16
    2 conv     32  3 x 3 / 1   208 x 208 x  16   ->   208 x 208 x  32  0.399 BFLOPs
    3 max          2 x 2 / 2   208 x 208 x  32   ->   104 x 104 x  32
    4 conv     64  3 x 3 / 1   104 x 104 x  32   ->   104 x 104 x  64  0.399 BFLOPs
    5 max          2 x 2 / 2   104 x 104 x  64   ->    52 x  52 x  64
    6 conv    128  3 x 3 / 1    52 x  52 x  64   ->    52 x  52 x 128  0.399 BFLOPs
    7 max          2 x 2 / 2    52 x  52 x 128   ->    26 x  26 x 128
    8 conv    256  3 x 3 / 1    26 x  26 x 128   ->    26 x  26 x 256  0.399 BFLOPs
    9 max          2 x 2 / 2    26 x  26 x 256   ->    13 x  13 x 256
   10 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512  0.399 BFLOPs
   11 max          2 x 2 / 1    13 x  13 x 512   ->    13 x  13 x 512
   12 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs
   13 conv    256  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 256  0.089 BFLOPs
   14 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512  0.399 BFLOPs
   15 conv    255  1 x 1 / 1    13 x  13 x 512   ->    13 x  13 x 255  0.044 BFLOPs
   16 yolo
   17 route  13
   18 conv    128  1 x 1 / 1    13 x  13 x 256   ->    13 x  13 x 128  0.011 BFLOPs
   19 upsample            2x    13 x  13 x 128   ->    26 x  26 x 128
   20 route  19 8
   21 conv    256  3 x 3 / 1    26 x  26 x 384   ->    26 x  26 x 256  1.196 BFLOPs
   22 conv    255  1 x 1 / 1    26 x  26 x 256   ->    26 x  26 x 255  0.088 BFLOPs
   23 yolo
Loading weights from yolov3-tiny.weights...Done!
data/dog.jpg: Predicted in 0.239507 seconds.
dog: 56%
car: 52%
truck: 56%
car: 62%
bicycle: 58%


8. 资源不够时可选应对方案

Nano的内存还是太小了，有时候需要swap扩一下内存.nano重启后，swap空间自动回收。

# 先禁用以前的
sudo swapoff /swapfile
 
# 修改swap 空间的大小为4G
sudo dd if=/dev/zero of=/swapfile bs=1M count=4096
 
# 设置文件为“swap file”类型
sudo mkswap /swapfile
 
# 启用swapfile
sudo swapon /swapfile



玩转Jetson Nano（六）安装caffe2
https://caffe2.ai/docs/getting-started.html?platform=ubuntu&configuration=compile
安装
欢迎来到Caffe2！立即开始深入学习，按照如何下载和安装Caffe2的分步指南。

选择首选平台并安装类型。
我们测试了最新的代码

Ubuntu 14.04
Ubuntu 16.04
安装依赖项
sudo apt update
sudo apt install -y --no-install-recommends \
      build-essential \
      git \
      libgoogle-glog-dev \
      libgtest-dev \
      libiomp-dev \
      libleveldb-dev \
      liblmdb-dev \
      libopencv-dev \
      libopenmpi-dev \
      libsnappy-dev \
      libprotobuf-dev \
      openmpi-bin \
      openmpi-doc \
      protobuf-compiler \
      python-dev \
      python-pip                          
pip install --user \
      future \
      numpy \
      protobuf \
      typing \
      hypothesis
pip install typing
注意libgflags2是针对Ubuntu 14.04。libgflags-dev适用于Ubuntu 16.04。
# for Ubuntu 14.04
sudo apt install -y --no-install-recommends \
      libgflags2 \
      cmake3
# for Ubuntu 16.04
sudo apt install -y --no-install-recommends \
      libgflags-dev \
      cmake

如果您有GPU，请在继续之前按照这些附加步骤操作。
使用GPU支持安装

克隆与构建
git clone https://github.com/pytorch/pytorch.git && cd pytorch
git submodule update --init --recursive
cmake -DUSE_NCCL=OFF
python3 setup.py install

测试Caffe2安装＃
运行此命令以查看您的Caffe2安装是否成功。
cd ~ && python -c 'from caffe2.python import core' 2>/dev/null && echo "Success" || echo "Failure"


源码编译caffe2

# 复制caffe2（caffe2和pytorch合并了...嘻嘻嘻~）
git clone --recursive https://github.com/pytorch/pytorch.git && cd pytorch 

git submodule update --init 
mkdir build && cd build

# 安装caffe2
cmake .. -DUSE_NCCL=OFF
sudo make install -j4

# 添加PYTHON环境变量
vim ~/.bashrc
export PYTHONPATH=/home/kaka/pytorch/build${PYTHONPATH:+:${PYTHONPATH}}

如果失败，那么通过在主目录中运行from caffe2.python import corePython 然后在Python中运行来获得更好的错误消息。

如果失败并显示有关未找到caffe2.python或未找到libcaffe2.so的消息，请参阅此信息，了解Caffe2如何在Python中安装。

如果您安装了GPU支持，请使用此命令测试GPU构建是否成功（从顶级pytorch目录运行）。您将以任一方式获得测试输出，但如果使用CPU而不是GPU，它将在输出顶部警告您，以及其他错误，例如缺少库。

python caffe2/python/operator_test/activation_ops_test.py

删软件
pip3 uninstall typing
pip3 uninstall hypothesis
装软件
pip3 install typing --user
pip3 install hypothesis --user


pip show hypothesis
hypothesis为提示少的库，下面为查看库信息，返回版本和路径代表已安装，没有代表未安装，用pip install 库名，安装就好。已安装还是报错，用下面命令添加环境变量。
sudo vim /usr/local/lib/python3.6/python3_path.pth
/home/love/.local/lib/python3.6/site-packages

其它
import sys
sys.path.append("/home/love/.local/lib/python3.6/site-packages")
使用GPU支持安装

如果您计划仅使用GPU而不是CPU，那么您应该安装NVIDIA CUDA 8和cuDNN v5.1或v6.0，这是一个用于深度神经网络的GPU加速原语库。 NVIDIA的详细说明或者如果您感觉幸运，请尝试下面的快速安装命令集。

首先更新您的显卡驱动程序！否则，您可能会遇到各种难以诊断的错误。
对于Ubuntu 16.04
sudo apt update && sudo apt install wget -y --no-install-recommends
wget "https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu1604/ppc64el/cuda-repo-ubuntu1604_10.0.130-1_ppc64el.deb"
sudo dpkg -i cuda-repo-ubuntu1604_10.0.130-1_ppc64el.deb
sudo apt update
sudo apt install cuda

安装cuDNN（所有Ubuntu版本）＃
版本5.1
CUDNN_URL="http://developer.download.nvidia.com/compute/redist/cudnn/v5.1/cudnn-8.0-linux-x64-v5.1.tgz"
wget ${CUDNN_URL}
sudo tar -xzf cudnn-8.0-linux-x64-v5.1.tgz -C /usr/local
rm cudnn-8.0-linux-x64-v5.1.tgz && sudo ldconfig

版本6.0 访问NVIDIA的cuDNN下载以注册和下载存档。按照上面相同的说明切换出更新的库。

请注意，安装CUDA和CuDNN会使您的构建大小增加大约4GB，因此计划为您的Ubuntu磁盘大小至少12GB。

设置教程和Jupyter服务器＃
如果您在云计算机上运行此操作，则默认情况下您可能没有UI或方式来查看IPython笔记本。通常情况下，您可以在本地启动它们，ipython notebook然后您会看到一个localhost：8888网页，其中会显示正在运行的笔记本目录。以下示例将向您展示如何启动Jupyter服务器并通过SSH隧道远程连接。

首先将云服务器配置为接受端口8889或任何您想要的端口，但在以下命令中更改端口。在AWS上，您可以通过向服务器的安全组添加规​​则来实现此目的，允许在端口8889上进行TCP入站。否则，您将为此调整iptables。

接下来，启动Juypter服务器。
jupyter notebook --no-browser --port=8889

然后创建SSH隧道。这会将云服务器的Jupyter实例传递到localhost 8888端口，供您在本地使用。下面的示例是根据您如何连接AWS，your-public-cert.pem您自己的公共证书在哪里以及ubuntu@super-rad-GPU-instance.compute-1.amazonaws.com您登录云服务器的模板。您可以通过转到Instances> Connect并在之后复制零件ssh并在下面的命令中交换它，轻松地在AWS上获取此信息。

ssh -N -f -L localhost:8888:localhost:8889 -i "your-public-cert.pem" ubuntu@super-rad-GPU-instance.compute-1.amazonaws.com





玩转Jetson Nano（六）安装caffe
进入正文之前先说一个心得，昨天训练一个人脸识别模型，发现不一会就OOM异常，就是资源耗尽的异常。运行free -m一看，我的天啊，free内存只有不到400M。想了很多办法都不行，后来直接把ubuntu的桌面禁用，效果感人啊！！内存从300多M一下子到了3.3G有木有！！！

beckhans@Jetson:~$ free -h
              total        used        free      shared  buff/cache   available
Mem:           3.9G        335M        3.3G         17M        234M        3.4G
Swap:            0B          0B          0B
# ubuntu关闭图形用户界面
sudo systemctl set-default multi-user.target
sudo reboot
 
# ubuntu启用图形用户界面
sudo systemctl set-default graphical.target
sudo reboot
（一）准备工作

在写本文之前我层N次安装caffe失败，都留下阴影了。好几次都想不用算了，但是caffe的例子实在是多，欲罢不能，硬着头皮趟出一条路。

1. 安装CUDA，cuDNN，以及OpenCV，nano已经将这些安装好了，但是需要配置一下，如何配置请看前文吧。下面列出如何检查这三样成功安装

 # 检查CUDA
nvcc -V    
 
 # 检查opencv
pkg-config opencv --modversion
 
 
# 检查cuDNN
cd /usr/src/cudnn_samples_v7/mnistCUDNN   #进入例子目录
sudo make -j 4     #编译一下例子
sudo chmod a+x mnistCUDNN # 为可执行文件添加执行权限
./mnistCUDNN # 执行
2. 创建Swap交换空间，不用Swap我一次都没有成功过，但是禁用桌面后能不能成功我还没试过。而且Swap空间还不能设的太大，我有一次设了10G，系统直接无法启动，不知道是不是Swap的原因

# 先禁用以前的
sudo swapoff /swapfile
 
# 修改swap 空间的大小为4G
sudo dd if=/dev/zero of=/swapfile bs=1M count=4096
 
# 设置文件为“swap file”类型
sudo mkswap /swapfile
 
# 启用swapfile
sudo swapon /swapfile
3.安装依赖包

sudo apt install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler
 
sudo apt install --no-install-recommends libboost-all-dev
 
sudo apt install libopenblas-dev liblapack-dev libatlas-base-dev
 
sudo apt install libgflags-dev libgoogle-glog-dev liblmdb-dev
 
sudo apt install git cmake build-essential
（二）开始安装caffe

https://www.nvidia.cn/object/caffe-installation-cn.html

如何在 NVIDIA GPU 上下载并安装
运行 CAFFE 的系统要求
Caffe 的 GPU 驱动版本具有以下要求：

64 位 Linux（本指南针对 Ubuntu 14.04 编写）
NVIDIA® CUDA® 7.5 ( NVIDIA Pascal™ GPU 要求使用 CUDA 8.0)
cuDNN v5.1
您还将需要支持计算功能的 NVIDIA GPU3.0 或更高版本。
如何下载并安装 Caffe
第 1 步：安装 CUDA
要结合使用 Caffe 和 NVIDIA GPU，步要安装CUDA 工具包。

第 2 步：安装 cuDNN
安装 CUDA 工具包后，下载适用于 Linux 的cuDNN v5.1 库（请注意，您将需要注册加速计算开发人员计划）。

下载后，解压缩文件并将其复制到 CUDA 工具包目录（此处假设在 /usr/local/cuda/ 中）：

$ sudo tar -xvf cudnn-8.0-linux-x64-v5.1.tgz -C /usr/local
第 3 步：安装依赖项
Caffe 依赖于多个库，您应该从您系统的数据包管理器获得这些库。

在 Ubuntu 14.04 中，将使用以下命令安装必要的库：

$ sudo apt install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev libatlas-base-dev git

$ sudo apt install --no-install-recommends libboost-all-dev

安装依赖
sudo apt install libturbojpeg
sudo ln -s /usr/lib/aarch64-linux-gnu/libturbojpeg.so.0.1.0 /usr/lib/aarch64-linux-gnu/libturbojpeg.so

sudo apt install libturbojpeg0-dev
sudo apt install -y python-pip
# sudo apt install -y python-opencv
# sudo apt install kate
第 4 步：安装 NCCL
在多个 GPU 上运行 Caffe 需要使用 NVIDIA NCCL。可使用以下命令安装 NCCL：

$ git clone https://github.com/NVIDIA/nccl.git
$ cd nccl
$ sudo make install -j4
$ sudo ldconfig

wget -c https://github.com/NVIDIA/nccl/archive/v2.4.8-1.tar.gz
mv v2.4.8-1.tar.gz nccl.v2.4.8-1.tar.gz
tar -zxf nccl.v2.4.8-1.tar.gz
cd nccl-2.4.8-1
sudo make install -j4
sudo ldconfig
NCCL 库和文件头将安装在 /usr/local/lib 和 /usr/local/include 中。


第 5 步：安装 Caffe
我们建议安装 NVIDIA 发布的新版 Caffe，请访问 https://github.com/NVIDIA/caffe/releases 获取新版本。截至发稿时，超级新版本为 0.15.9。
git clone https://github.com/BVLC/caffe.git
git clone https://github.com/NVIDIA/caffe.git
$ wget -c https://github.com/NVIDIA/caffe/archive/v0.17.3.tar.gz

$ tar -zxf v0.17.3.tar.gz

$ cd caffe-0.17.3

$ cp Makefile.config.example Makefile.config

在文本编辑器中打开新创建的 Makefile.config，然后进行以下更改：
vim Makefile.config
# 将下面三句前面的注释符号去掉
USE_CUDNN := 1        #这可以启用 cuDNN 加速。
# USE_NCCL := 1         #暂时不要打开，不然nano会编译失败，这可以启用在多个 GPU 上运行 Caffe 所需的 NCCL。
OPENCV_VERSION := 3   
WITH_PYTHON_LAYER := 1



# 修改路径，注释掉原来的，换成新的
#INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include
#LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib 
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial
LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/aarch64-linux-gnu /usr/lib/aarch64-linux-gnu/hdf5/serial

把py2.7的改成py3.6

# 编译caffe进行make runtest遇到caffe error == cudaSuccess (48 vs. 0)的问题
# 针对的板卡平台为Jetson TX1和Jetson Nano，cuda分别为CUDA9.0和CUDA10.0。
# 将下面这段话中20和21那部分删掉，添加一行53如下
CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \
                -gencode arch=compute_35,code=sm_35 \
                -gencode arch=compute_50,code=sm_50 \
                -gencode arch=compute_52,code=sm_52 \
                -gencode arch=compute_53,code=sm_53 \
                -gencode arch=compute_60,code=sm_60 \
                -gencode arch=compute_61,code=sm_61 \
                -gencode arch=compute_61,code=compute_61 
# 为什么添加这么一行，是因为我发现TX1和Nano的GPU的算力能力都是5.3，所以这么做了，结果发现可以解决这个错误，哈哈。
# 这个报错应该和GPU的算力能力有关系，注意先到官网查看自己GPU平台算力再做相应修改。
# 48 error = cudaSucess (48 vs. 0) no kernel image is available for execution on the device 
# cuda 9.0以上不支持计算能为小于3的显卡,换cuda 8.0就可以了。


修改 caffe 目录下的 Makefile 文件：
vim Makefile
在Makefile文件的第197行，把 hdf5_hl 和hdf5修改为hdf5_serial_hl 和 hdf5_serial
# 这一句在185行
LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial


# 这一句在443行
NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)
 


保存并关闭文件。现在，您可以编译 Caffe 了。


清理编译

make clean

重新编译，4个线程

$ make all -j4
完成此命令后，您会在 build/tools/caffe 中获得 Caffe 二进制文件。



Caffe学习系列(9)：运行caffe自带的两个简单例子
为了程序的简洁，在caffe中是不带练习数据的，因此需要自己去下载。但在caffe根目录下的data文件夹里，作者已经为我们编写好了下载数据的脚本文件，我们只需要联网，运行这些脚本文件就行了。

注意：在caffe中运行所有程序，都必须在根目录下进行，否则会出错

1、mnist实例

mnist是一个手写数字库，由DL大牛Yan LeCun进行维护。mnist最初用于支票上的手写数字识别, 现在成了DL的入门练习库。征对mnist识别的专门模型是Lenet，算是最早的cnn模型了。

mnist数据训练样本为60000张，测试样本为10000张，每个样本为28*28大小的黑白图片，手写数字为0-9，因此分为10类。

首先下载mnist数据，假设当前路径为caffe根目录

# sudo sh data/mnist/get_mnist.sh
运行成功后，在 data/mnist/目录下有四个文件：

train-images-idx3-ubyte:  训练集样本 (9912422 bytes) 
train-labels-idx1-ubyte:  训练集对应标注 (28881 bytes) 
t10k-images-idx3-ubyte:   测试集图片 (1648877 bytes) 
t10k-labels-idx1-ubyte:   测试集对应标注 (4542 bytes)

这些数据不能在caffe中直接使用，需要转换成LMDB数据

# sudo sh examples/mnist/create_mnist.sh
如果想运行leveldb数据，请运行 examples/siamese/ 文件夹下面的程序。 examples/mnist/ 文件夹是运行lmdb数据

转换成功后，会在 examples/mnist/目录下，生成两个文件夹，分别是mnist_train_lmdb和mnist_test_lmdb，里面存放的data.mdb和lock.mdb，就是我们需要的运行数据。

接下来是修改配置文件，如果你有GPU且已经完全安装好，这一步可以省略，如果没有，则需要修改solver配置文件。

需要的配置文件有两个，一个是lenet_solver.prototxt，另一个是train_lenet.prototxt.

首先打开lenet_solver_prototxt

# sudo vi examples/mnist/lenet_solver.prototxt
根据需要，在max_iter处设置最大迭代次数，以及决定最后一行solver_mode,是否要改成CPU

保存退出后，就可以运行这个例子了

# sudo time sh examples/mnist/train_lenet.sh
CPU运行时候大约13分钟，GPU运行时间大约4分钟，GPU+cudnn运行时候大约40秒，精度都为99%左右
# 测试模型 
sudo ./build/tools/caffe.bin test -model=examples/mnist/lenet_train_test.prototxt -weights=examples/mnist/lenet_iter_100.caffemodel -iterations=100
2、cifar10实例

cifar10数据训练样本50000张，测试样本10000张，每张为32*32的彩色三通道图片，共分为10类。

下载数据：

# sudo sh data/cifar10/get_cifar10.sh
运行成功后，会在 data/cifar10/文件夹下生成一堆bin文件

转换数据格式为lmdb：

# sudo sh examples/cifar10/create_cifar10.sh
转换成功后，会在 examples/cifar10/文件夹下生成两个文件夹，cifar10_train_lmdb和cifar10_test_lmdb, 里面的文件就是我们需要的文件。

为了节省时间，我们进行快速训练（train_quick)，训练分为两个阶段，第一个阶段（迭代4000次）调用配置文件cifar10_quick_solver.prototxt, 学习率（base_lr)为0.001

第二阶段（这里要修改迭代1000次）调用配置文件cifar10_quick_solver_lr1.prototxt, 学习率(base_lr)为0.0001

前后两个配置文件就是学习率(base_lr)和最大迭代次数（max_iter)不一样，其它都是一样。如果你对配置文件比较熟悉以后，实际上是可以将两个配置文件合二为一的，设置lr_policy为multistep就可以了。

复制代码
base_lr: 0.001
momentum: 0.9
weight_decay: 0.004
lr_policy: "multistep"
gamma: 0.1
stepvalue: 4000
stepvalue: 5000
复制代码
运行例子：

# sudo time sh examples/cifar10/train_quick.sh
GPU+cudnn大约45秒左右，精度75%左右。







准备图像数据库
测试 Caffe 的训练性能需要使用图像数据库作为输入资源。Caffe 自带多个模型，可使用来自 ILSVRC12 挑战赛（“ImageNet”）的图像。原始图像文件可从 //image-net.org/download-images 下载（您将需要开通帐户并同意其条款）。下载原始图像文件并解压到您的系统中后，请继续执行以下步骤。假设原始图像以如下方式存储在您的磁盘中：

/path/to/imagenet/train/n01440764/n01440764_10026.JPEG

/path/to/imagenet/val/ILSVRC2012_val_00000001.JPEG
第 6 步：下载辅助数据
$ ./data/ilsvrc12/get_ilsvrc_aux.sh
第 7 步：创建数据库
首先从网上下载需要的数据集并解压到caffe同级目录下。下载地址，百度网盘：https://pan.baidu.com/s/1o77w1wI
unzip image1000test200.zip
cd caffe/examples
mkdir myfile4
cd myfile4/
mkdir data
cd data/
cp -rf ../../../../image1000test200/train ./
cp -rf ../../../../image1000test200/val ./

cd ../../../

在文本编辑器中打开文件 examples/imagenet/create_imagenet.sh，然后进行以下更改：
vim ./examples/imagenet/create_imagenet.sh
TRAIN_DATA_ROOT=./examples/myfile4/data/train/
VAL_DATA_ROOT=./examples/myfile4/data/val/
将变量 TRAIN_DATA_ROOT 和 VAL_DATA_ROOT 更改为您解压原始图像的路径。

设置 RESIZE=true 以便在将图像添加到数据库之前将其调整到适当大小。

保存并关闭文件。现在，您可以使用以下命令创建图像数据库了：
./examples/imagenet/create_imagenet.sh

然后，使用以下命令创建所需的图像均值文件：
./examples/imagenet/make_imagenet_mean.sh






首先从网上下载需要的数据集并解压。下载地址，百度网盘：https://pan.baidu.com/s/1o77w1wI
cd examples
mkdir myfile4
cd myfile4/
mkdir data
cd data/
cp -rf ../../../../image1000test200/train ./
cp -rf ../../../../image1000test200/val ./
vim ../create_filelist.sh
cd ..
chmod 777 create_filelist.sh
cd ../..
./examples/myfile4/create_filelist.sh
cd examples/myfile4/
vim create_lmdb.sh
chmod 777 create_lmdb.sh
cd ../..
./examples/myfile4/create_lmdb.sh
cd examples/myfile4/
vim create_meanfile.sh
chmod 777 create_meanfile.sh
cd ../..
./examples/myfile4/create_meanfile.sh
cd examples/myfile4/
vim myfile4_train_test.prototxt
vim myfile4_solver.prototxt
chmod 777 myfile4_train_test.prototxt
chmod 777 myfile4_solver.prototxt
cd ../..

build/tools/caffe train -solver examples/myfile4/myfile4_solver.prototxt




cifar10训练步骤如下：

（1）打开终端，应用cd切换路径，如 cd ~/caffe/data/cifar10 ，

（2）继续执行命令   ./get_cifar10.sh，

（3）成功下载数据集之后，执行ls即可见所下载的数据文件，

（4）再次将路径切换到cd ~/caffe/examples/cifar10

（5）继续执行命令 ./create_cifar10.sh 

此时系统报错./build/examples/cifar10/convert_cifar_data.bin: not found ，这是因为当前目录在/caffe/examples/cifar10 ，而执行./create_cifar10.sh ，需要在caffe目录下，因此我们需要切换到caffe目录下，然后执行./examples/cifar10/create_cifar10.sh 

(6) 同理，在caffe目录下执行./examples/cifar10/train_quick.sh ,此时就不会报错找不到 ./build/tools/caffe 了。











查找文件
安装查找功能
sudo apt install mlocate
更新数据
sudo updatedb
开始查找
locate hdf5.h




sudo apt install libtasn1-6 libtasn1-6-dev libtasn1-bin

wget -c ftp://ftp.gnu.org/gnu/libtasn1/libtasn1-4.13.tar.gz
tar -xzvf libtasn1-4.13.tar.gz
cd libtasn1-4.13/
./configure
make -j 4
sudo make install



wget -c ftp://ftp.gnu.org/gnu/libunistring/libunistring-0.9.10.tar.gz
tar -xzvf libunistring-0.9.10.tar.gz
cd libunistring-0.9.10
./configure
make -j 4
sudo make install




wget -c https://nlnetlabs.nl/downloads/unbound/unbound-latest.tar.gz
tar zxf unbound-latest.tar.gz && cd unbound-1.9.2/
./configure --prefix=/usr --sysconfdir=/etc && make -j 4 && sudo make install
cd ..





https://p11-glue.freedesktop.org/p11-kit.html
git clone https://github.com/p11-glue/p11-kit
cd p11-kit/







wget -c https://www.gnupg.org/ftp/gcrypt/gnutls/v3.6/gnutls-3.6.8.tar.xz
xz -d gnutls-3.6.8.tar.xz && tar -xvf gnutls-3.6.8.tar && cd gnutls-3.6.8
./configure --prefix=/usr --disable-openssl --enable-shared --enable-mini-gmp
make
sudo make install


git clone -b master git://git.sv.gnu.org/emacs.git
因为前面编译过，所以运行make clean ，make distclean 来清理一下， 再重新运行./configure ，make ，sudo make install ，这回就完全安装成功了



编译参考  可删除
https://blog.csdn.net/jbl5501328/article/details/82563434

libnice linux编译流程
2018年09月10日 00:35:03 hijiang1 阅读数：308
写于2018-09-09，以便参考是哪个版本的libnice；

libnice的linux编译，也有各种坑，记录下以便大家采坑；

1、git clone https://gitlab.freedesktop.org/libnice/libnice.git

2、cd libnice，查看readme，里面有提示依赖的其他库

Requirements
------------

 glib >= 2.44
 pkg-config
 gnutls >= 2.12.0
 gupnp-igd >= 0.1.2 (optional)
 gstreamer-0.10 >= 0.10.0 (optional)
 gstreamer-1.0 (optional)

Build instructions

3、wget http://ftp.gnome.org/pub/gnome/sources/glib/2.48/glib-2.48.1.tar.xz 

tar -xvf glib-2.48.1.tar.xz

cd glib-2.48.1

./autogen.sh提示：没安装gtk-doc

4、运行
sudo apt install gtk-doc-tools

5、下载
wget -c https://nchc.dl.sourceforge.net/project/libpng/zlib/1.2.11/zlib-1.2.11.tar.gz

tar -zxvf zlib-1.2.11.tar.gz

cd zlib-1.2.11

./configure
make -j 4
sudo make install

提示：configure: error: Package requirements (libpcre >= 8.13) were not met:

好吧，接着下pcre：
wget -c https://sourceforge.net/projects/pcre/files/pcre/8.42/pcre-8.42.zip

unzip pcre-8.42.zip
cd pcre-8.42
./configure --enable-utf8 --enable-unicode-properties（一定加上两个选项）
make -j 4
sudo make install
6、接着回来到glib目录

./autogen.sh

make -j 4 && sudo make install

7、回到libnice目录

接着要安装gnutls >= 2.12.0

wget ftp://ftp.gnutls.org/gcrypt/gnutls/v3.5/gnutls-3.5.0.tar.xz下载

./configure

又提示：Libnettle 3.1 was not found.没有
wget -c https://ftp.gnu.org/gnu/nettle/nettle-3.5.1.tar.gz
tar -xzvf nettle-3.5.1.tar.gz
cd nettle-3.5.1/
./configure --prefix=/usr --disable-static
make -j 4
sudo make install &&
sudo chmod   -v   755 /usr/lib/lib{hogweed,nettle}.so &&
install -v -m755 -d /usr/share/doc/nettle-3.5.1 &&
install -v -m644 nettle.html /usr/share/doc/nettle-3.5.1
如果
pkg-config --modversion nettle
没有更新版本
则
locate nettle.pc
搜索位置，用下面方式
sudo mv /usr/lib/pkgconfig/nettle.pc /usr/lib/pkgconfig/nettle.pc.bak
sudo ln -s /usr/lib/aarch64-linux-gnu/pkgconfig/nettle.pc /usr/lib/pkgconfig/nettle.pc

wget -c https://ftp.gnu.org/gnu/nettle/nettle-3.4.1.tar.gz
tar -xzvf nettle-3.4.1.tar.gz
cd nettle-3.4.1/
./configure --prefix=/usr --disable-openssl --enable-shared --enable-mini-gmp
make -j 4
sudo make install

8、wget http://ftp.gnu.org/gnu/nettle/nettle-3.1.tar.gz
tar -zxvf nettle-3.1.tar.gz
cd nettle-3.1
./configure
make -j 4
sudo make install
9、回到gnutls

./configure 

Libhogweed (nettle's companion library) was not found. Note that you must compile nettle with gmp support.

好吧，网上查，是因为nettle安装不正确，可是找半天没找到hogweed,而且需要gmp support；

看了下gnutls的README，偶然发现这句话：

cd nettle-<version>
    ./configure --prefix=/usr --disable-openssl --enable-shared --enable-mini-gmp
    make
    sudo make install

好吧，看来要指定安装目录，而且要是shared的，重新编译nettle吧

10、重新回到gnutls

./configure

提示：gmp was not found

11、运行：sudo apt install libgmp-dev

12、在到gnutls：

./configure

又提示： Libtasn1 4.3 was not found.

wget ftp://ftp.gnu.org/gnu/libtasn1/libtasn1-4.4.tar.gz

./configure && make && make install

12、回到gnutls

./configure

还提示：p11-kit >= 0.23.1

13、wget https://github.com/p11-glue/p11-kit/archive/0.23.10.tar.gz
git clone https://github.com/p11-glue/p11-kit.git

./configure && make && sudo make install

14、回到gnutls

总算通过了

15、回到libnice目录

./autogen.sh

make -j8

ok总算编译成功了



参考结束







安装多线程下载软件，支持断点下载，wget支持断点加-c
包地址：http://pkgs.repoforge.org/axel/
sudo apt install axel

主要参数
-n x：启动x个线程下载

-s x：最大速度（byte/s）为x

-o f：指定输出文件

-S [x]：搜索境像并且从指定的x服务器（可以是多个）下载

-U x：设置user agent

-N：不合用代理服务器

-q：静默退出

-v：更多状态信息

-h：帮助信息

-v：版本
--max-speed = x -s x指定最大速度（每秒字节数）
--num-connections = x -n x指定最大连接数
--max-redirect = x指定最大重定向数
--output = f -o f指定本地输出文件
--search [= n] -S [n]搜索镜像并从n个服务器下载
--ipv4 -4使用IPv4协议
--ipv6 -6使用IPv6协议
--header = x -H x添加HTTP标头字符串
--user-agent = x -U x设置用户代理
--no-proxy -N只是不要使用任何代理服务器
--insecure -k不验证SSL证书
--no-clobber -c如果文件已存在则跳过下载
--quiet -q单独留下stdout
--verbose -v更多状态信息
--alternate -a替代进度指示器
--help -h这个信息
--timeout = x -T x设置I / O和连接超时
--version -V版本信息




断点续传
直接再次执行下载命令，自动从上次下载的位置开始下载

示例
$ axel -n 10 http://xxx.xxx.xxx.xxx/xxx.xxx
图像数据库
axel -n 10 http://image-net.org/imagenet_data/urls/imagenet_fall09_urls.tgz

axel -n 10 http://image-net.org/imagenet_data/urls/imagenet_spring10_urls.tgz

axel -n 10 http://image-net.org/imagenet_data/urls/imagenet_winter11_urls.tgz

axel -n 10 http://image-net.org/imagenet_data/urls/imagenet_fall11_urls.tgz


tar -xzvf imagenet_fall09_urls.tgz
tar -xzvf imagenet_spring10_urls.tgz
tar -xzvf imagenet_fall11_urls.tgz
tar -xzvf imagenet_winter11_urls.tgz

先处理下文本
在notepad++中替换，选择使用表达式
查找.*http
替换http
会卡住，不要动，等它自己替换好恢复

批量下载图片示例
wget -c -i spring10_urls.txt

批量下载
方法1：

#!/bin/sh -e
# usage:  ./axel-batch.sh the-download-url.list
cat $1 | xargs -l1 axel -n8 -a

方法2:
#!/bin/sh -e
# usage:  ./axel-batch.sh the-download-url.list
cat $1 | while read LINE
do
        if [ -n "$LINE" ]; then
        axel -n8 -a `echo $LINE`
        fi
done


解压lz文件
sudo apt install lzip




安装m4

m4源码下载
git clone git://git.sv.gnu.org/m4
git clone http://git.savannah.gnu.org/r/m4.git

wget http://mirrors.kernel.org/gnu/m4/m4-1.4.18.tar.gz
tar -xzvf m4-1.4.18.tar.gz
cd m4-1.4.18
sudo ./configure --prefix=/usr/local/m4-1.4.18
sudo make -j 4
sudo make install




安装autoconf
git clone http://git.savannah.gnu.org/r/autoconf.git
git clone git://git.sv.gnu.org/autoconf
git clone http://git.sv.gnu.org/r/autoconf.git

cd ~
wget http://mirrors.kernel.org/gnu/autoconf/autoconf-latest.tar.gz
tar -xzvf autoconf-latest.tar.gz
cd autoconf-2.69/
sudo ./configure --prefix=/usr/local/autoconf-2.69
sudo make -j 4
sudo make install



安装automake

git clone https://git.savannah.gnu.org/git/automake.git

wget http://mirrors.kernel.org/gnu/automake/automake-1.16.1.tar.gz
tar -xzvf automake-1.16.1.tar.gz
cd automake-1.16.1/
sudo ./configure --prefix=/usr/local/automake-1.16.1
sudo make -j 4
sudo make install



安装libtool
wget http://mirrors.kernel.org/gnu/libtool/libtool-2.4.6.tar.gz
tar -xzvf libtool-2.4.6.tar.gz
cd libtool-2.4.6/
sudo ./configure --prefix=/usr/local/libtool-2.4.6
sudo make -j 4
sudo make install

mkdir gmp-mpfr-mpc
cd gmp-mpfr-mpc/

wget ftp://ftp.gnu.org/gnu/gmp/gmp-6.1.2.tar.xz
wget http://www.mpfr.org/mpfr-current/mpfr-4.0.2.tar.gz
wget https://ftp.gnu.org/gnu/mpc/mpc-1.1.0.tar.gz
xz -d gmp-6.1.2.tar.xz
tar -zxvf mpc-1.1.0.tar.gz
tar -zxvf mpfr-4.0.2.tar.gz
tar -xvf gmp-6.1.2.tar

# a、安装GMP
sudo mkdir /usr/local/gmp-6.1.2
cd gmp-6.1.2
sudo ./configure --prefix=/usr/local/gmp-6.1.2 --enable-cxx
sudo make -j 4
# sudo make check  //校验，不用执行
sudo make install

# b、安装MPFR
cd ../mpfr-4.0.2
sudo mkdir /usr/local/mpfr-4.0.2
sudo ./configure --prefix=/usr/local/mpfr-4.0.2 --with-gmp=/usr/local/gmp-6.1.2
sudo make -j 12
sudo make install

# c、安装MPC
cd ../mpc-1.1.0
sudo mkdir /usr/local/mpc-1.1.0
sudo ./configure --prefix=/usr/local/mpc-1.1.0 --with-gmp=/usr/local/gmp-6.1.2 --with-mpfr=/usr/local/mpfr-4.0.2
sudo make -j 12
sudo make install

# 用下面方法【对所有用户永久生效】
sudo vim /etc/ld.so.conf
# 将下面内容填入
/usr/local/gmp-6.1.2/lib
/usr/local/mpfr-4.0.2/lib
/usr/local/mpc-1.1.0/lib
# 退出执行
sudo ldconfig






安装编译依赖包
sudo apt install nasm

libjpeg-turbo源码编译、安装
libjpeg-turbo是libjpeg的一个复刻，它采用单指令流多数据流（SIMD）指令来加速JPEG编码和解码基础效率。许多项目现在使用libjpeg-turbo而不是libjpeg。
libjpeg-turbo源码下载，官方网址：https://libjpeg-turbo.org/，从官方主页列出的GitHub地址：https://github.com/libjpeg-turbo/libjpeg-turbo里的release标签页选择版本进行下载。

git clone https://github.com/libjpeg-turbo/libjpeg-turbo.git
wget https://codeload.github.com/libjpeg-turbo/libjpeg-turbo/zip/master
unzip libjpeg-turbo-master.zip
cd libjpeg-turbo-master/
cmake -G"Unix Makefiles" -DCMAKE_INSTALL_PREFIX=/usr/local/libjpeg-turbo
sudo make -j 4
sudo make install










# 
# 

输入命令

cat /proc/version

显示如下

Linux version 4.10.0-28-generic (buildd@lgw01-12)         linux内核版本号

gcc version 5.4.0                                                                 gcc编译器版本号

Ubuntu 5.4.0-6ubuntu1                                                      Ubuntu版本号

输入命令

uname -a

显示linux的内核版本和系统是多少位的：X86_64代表系统是64位的。

输入命令

lsb_release -a

显示如下

Distributor ID: Ubuntu                           //类别是ubuntu

Description:  Ubuntu 16.04.3 LTS          //16年3月发布的稳定版本，LTS是Long Term Support：长时间支持版本，支持周期长达三至五年

Release:    16.04                                    //发行日期或者是发行版本号

Codename:   xenial                               //ubuntu的代号名称













cd jetson-inference/build/aarch64/bin
./imagenet-console orange_0.jpg output_0.jpg






sudo apt install subversion
sudo apt install m4



安装caffe时出错需要安装下面这个
程序“protoc”尚未安装。 您可以使用以下命令安装：
sudo apt install protobuf-compiler
sudo apt install python-pip
sudo apt install python3-pip

报错时在报错的一行前面加减号以忽略错误继续执行

pip安装出现Command "python setup.py egg_info" failed with error code 1 的解决方案
2018年01月13日 09:13:51 小白旗 阅读数：92606更多
个人分类： python
 版权声明：本文为博主原创文章，未经博主允许不得转载。	https://blog.csdn.net/qq_37788558/article/details/79049410
今天装matplot和pillow时安装报错，按错误提示去下载了一些预装包，但还是不行。

然后按照下边的方法更新安装插件，试了下，成功。

本文只提供本人的一些经验，不代表可以解决所有人的问题。

python -m pip install --upgrade --force pip --user
pip install setuptools==33.1.1 --user
python3 -m pip install --upgrade --force pip --user
pip3 install setuptools==33.1.1 --user
pip升级后Import Error:cannot import name main解决方案
2018年05月22日 19:29:05 ZONG_XP 阅读数：43373
版权声明：本文为博主原创文章，未经博主允许不得转载。	https://blog.csdn.net/zong596568821xp/article/details/80410416
在Ubuntu上安装软件，不小心升级了pip，导致使用时报错如下



后来发现是因为将pip更新为10.0.0后库里面的函数有所变动造成这个问题。 解决方法如下：



sudo gedit /usr/bin/pip

修改的内容如下：

//修改前
from pip import main  
if __name__ == '__main__':  
    sys.exit(main()) 
修改后
from pip import __main__  //这行也要修改
if __name__ == '__main__':  
    sys.exit(__main__._main())//增加__main__._

最后在终端输入pip -V，默认版本就是长10啦啦啦啦

大多数blog也有推荐说修改pip文件，可是细节不一样，我的话就这两种修改是有效的，至于部分说要先退出终端才能生效，其实是不需要的，修改pip配置文件后是马上生效的，毕竟若关闭了终端，不便于查找原因



还出错就先安装这个
pip install 'scikit-image<0.15' --user
升级PIP
python3 -m pip install --upgrade pip





sudo apt update
sudo apt install -y gfortran cython 
sudo apt install -y libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler git
sudo apt install --no-install-recommends libboost-all-dev
sudo apt install -y python-dev libgflags-dev libgoogle-glog-dev liblmdb-dev libatlas-base-dev python-skimage
sudo apt install -y python-pip
sudo apt install -y build-essential
sudo apt install -y cmake libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev
sudo apt install -y python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-22-dev

安装OpenCV
OpenCV还是必须要装的，这里我选一个2.4的OpenCV。

少废话，安pip包。

pip install pyzmq jsonschema pillow --user
pip install numpy scipy 
pip install ipython jupyter pyyaml --user

pip3 install pyzmq jsonschema pillow --user
pip3 install numpy scipy 
pip3 install ipython jupyter pyyaml --user
编译Caffe
先把Caffe拉下来：

cd ~
git clone https://github.com/BVLC/caffe
cd caffe
cp Makefile.config.example Makefile.config
vim Makefile.config

开始编译
make all -j4
make test -j4
make runtest -j4
然后就是漫长的等待，结束后加上也把Python的给编译了

cd python
pip install -r requirements.txt
make pycaffe -j4
然后在zsh或者bash环境中添加pycaffe的环境：

export PYTHONPATH=/home/ubuntu/extra/caffe/python:$PYTHONPATH

6.?安装Caffe
A.?下载caffe

cd ~
mkdir git  //在home下新建一个git文件夹，用来存放那些从github上git下来的文zong件
git clone https://github.com/BVLC/caffe.git    //从github上git caffe
B.?开始安装
cd caffe    //打开到刚刚git下来的caffecp Makefile.config.example Makefile.config 
//将Makefile.config.example的内容复制到Makefile.config
//因为make指令只能make   Makefile.config文件，而Makefile.config.example是caffe给出的makefile例子
gedit Makefile.config      //打开Makefile.config文件
仔细阅读makefile中的注释语句其实就知道该怎么操作了，这里贴出笔者的修改，也是大部分TX2用户的修改。
//若使用cudnn，则将# USE_CUDNN := 1
修改成：
USE_CUDNN := 1
 
//若使用的opencv版本是3的，则将# OPENCV_VERSION := 3
修改为：
OPENCV_VERSION := 3
 
//重要的一项
将# Whatever else you find you need goes here.下面的
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include
LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib
修改为：
INCLUDE_DIRS :=  $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial
LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/aarch64-linux-gnu /usr/lib/aarch64-linux-gnu/hdf5/serial
//这是因为ubuntu16.04的文件包含位置发生了变化，尤其是需要用到的hdf5的位置，所以需要更改 
C.?为hdf5创建链接

\\首先执行下面两句话：
find . -type f -exec sed -i -e 's^"hdf5.h"^"hdf5/serial/hdf5.h"^g' -e 's^"hdf5_hl.h"^"hdf5/serial/hdf5_hl.h"^g' '{}' \;
cd /usr/lib/aarch64-linux-gnu
\\这里笔者被坑了很多次，网上几乎所有的教程都是x86_64,给出的是cd /usr/lib/x86_64-linux-gnu，然而TX2并没有这个文件，浪费了笔者很多时间；
笔者没有找到用aarch架构的caffe安装文章，故写下了此博客
\\然后根据情况执行下面两句：
sudo ln -s libhdf5_serial.so.10.1.0 libhdf5.so
sudo ln -s libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so
\\注意：这里的10.1.0和10.0.2根据不同的系统可能对应的数字会不同，比如在ubuntu15.10中其数字就是8.0.2.
\\具体的数字可以在打开的文件中查看对应文件后面跟的数字
PS：查看当前目录下文件，用ls -a
D.?Make各种文件

cd ..   \\此时位置应该处于caffe文件夹下
make all -j4  //j4代表计算机cpu有4个核，因此可以多线程一起make，这样make的速度会快很多。TX2是4核的，我们就不要学别人用什么j8，j16了，乖乖地敲j4
make test -j4
make runtest -j4
make pycaffe   //如果以后用python来开发的话必须执行这一句，一般不管你是否用python，都会执行这一句
make distribute

LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_seria

sudo make clean
make all -j4





wget http://ftp.gnu.org/gnu/autogen/rel5.18.16/autogen-5.18.16.tar.gz
tar -xzvf autogen-5.18.16.tar.gz
cd autogen-5.18.16/
sudo mkdir /usr/local/autogen-5.18.16
sudo ./configure --prefix=/usr/local/autogen-5.18.16
sudo make -j 4
sudo make install

https://www.gnu.org/software/guile/download/
sudo apt install guile-2.2
apt install guile-2.0
git clone git://git.sv.gnu.org/guile.git  


跳过下面

wget ftp://ftp.gnu.org/gnu/guile/guile-2.2.4.tar.xz
xz -dk guile-2.2.4.tar.xz
tar -xvf guile-2.2.4.tar
cd guile-2.2.4/
apt-cache search Libtool
sudo apt install libltdl-dev
apt-cache search libunistring
sudo apt install libunistring2

apt-cache search libffi
sudo apt install libffi-dev
apt-cache search gc

清理结果重新编译
sudo make distclean


sudo mkdir /usr/local/guile-2.2.4
sudo ./configure --prefix=/usr/local/guile-2.2.4
make -j 4
sudo make install
其他一些命令
sudo apt update  更新源
sudo apt install package 安装包
sudo apt remove package 删除包
sudo apt-cache search package 搜索软件包
sudo apt-cache show package  获取包的相关信息，如说明、大小、版本等
sudo apt install package --reinstall  重新安装包
sudo apt -f install  修复安装
sudo apt remove package --purge 删除包，包括配置文件等
sudo apt build-dep package 安装相关的编译环境
sudo apt upgrade 更新已安装的包
sudo apt dist-upgrade 升级系统
sudo apt-cache depends package 了解使用该包依赖那些包
sudo apt-cache rdepends package 查看该包被哪些包依赖
sudo apt source package  下载该包的源代码
sudo apt clean && sudo apt autoclean 清理无用的包
sudo apt check 检查是否有损坏的依赖


sudo apt install libgmp-dev
sudo apt install libmpfr-dev


sudo apt-cache search package libunistring
sudo apt install libunistring-dev

https://www.jianshu.com/p/89702b13bc51
http://www.hboehm.info/gc/
要构建收集器的工作版本，您需要执行以下操作，其中D是安装目录的绝对路径：
cd git
git clone git://github.com/ivmai/bdwgc.git
cd bdwgc
git clone git://github.com/ivmai/libatomic_ops.git
autoreconf -vif
automake --add-missing
./configure
make -j 4
sudo make install
这将要求您已经安装了C和C ++工具链，git， automake，autoconf和libtool。

.libs / libguile_2.2_la-posix.o：在函数`scm_tmpnam'中：
/home/love/下载/yi-lai/guile/guile-2.2.4/libguile/posix.c:1574：警告：使用`tmpnam'很危险，最好使用`mkstemp'
在文件中加入头文件
 #include <string.h>
解决







显示gpio当前数据

gpio readall


https://my.oschina.net/freeblues/blog/196902



(defun sh (cmd)
    #+clisp
        (let ((str (ext:run-shell-command cmd :output:stream)))
            (loop for line = (read-line str nil)
             until (null line)
             do (print line)))
    #+ecl 
        (si:system cmd)
    #+sbcl 
        (sb-ext:run-program "/bin/sh" (list "-c" cmd) :input nil :output *standard-output*)
    #+clozure 
        (ccl:run-program "/bin/sh" (list "-c" cmd) :input nil :output *standard-output*))




实际举个例子，就以 CCL 为例好了：


CL-USER> (ccl:run-program "/bin/sh" (list "-c" "echo 123") :input nil :output *standard-output*)
123
#<EXTERNAL-PROCESS (/bin/sh -c echo 123)[2596] (EXITED : 0) #x30200197619D>
CL-USER>



控制gpio示例

导出引脚
(导出引脚 11)


设置为输出模式
(引脚模式 11 "out")

设置为输入模式
(引脚模式 11 "in")

设置为高电平
(输出值 11 1)

设置为低电平
(输出值 11 0)

关闭引脚
(关闭引脚 11)

读取数值

(读取值 11)



(defun 初始化 ()
	(导出引脚 13)
	(引脚模式 13 "out")
	(导出引脚 19)
	(引脚模式 19 "out")
	(导出引脚 20)
	(引脚模式 20 "out"))



(defun 闪灯 (int)
	(dotimes (x int)
	(输出值 13 1)
	(sleep 0.5)
	(输出值 13 0)
	(sleep 0.5)
	(输出值 19 1)
	(sleep 0.5)
	(输出值 19 0)
	(sleep 0.5)
	(输出值 20 1)
	(sleep 0.5)
	(输出值 20 0)
	(sleep 0.5)))


(defun 关闭引脚 ()
	(关闭引脚 13)
	(关闭引脚 19)
	(关闭引脚 20))




(defmacro 导出引脚 (pin)
	`(sh ,(format nil "echo ~a > ~a" pin "/sys/class/gpio/export")))



(defmacro 引脚模式 (pin mode)
	`(sh ,(format nil "echo ~a > ~a~a~a" mode "/sys/class/gpio/gpio" pin "/direction")))



(defmacro 输出值 (pin value)
	`(sh ,(format nil "echo ~a > ~a~a~a" value "/sys/class/gpio/gpio" pin "/value")))



(defmacro 关闭引脚 (pin)
	`(sh ,(format nil "echo ~a > /sys/class/gpio/unexport" pin)))



(defmacro 读取值 (pin)
	`(sh ,(format nil "cat ~a~a~a" "/sys/class/gpio/gpio" pin "/value")))




cd ..
rel5.18.16/
wget http://ftp.gnu.org/gnu/autogen/rel5.18.16/autogen-5.18.16.tar.gz
tar -xzvf autogen-5.18.16.tar.gz
cd autogen-5.18.16/
sudo ./configure --prefix=/usr/local/
sudo make -j 4
sudo make install
cd ..
wget ftp://ftp.gnu.org/gnu/guile/guile-2.2.4.tar.xz
xz -dk guile-2.2.4.tar.xz
tar -xvf guile-2.2.4.tar
cd guile-2.2.4/

编译器
gcc-4.4.7通过yum安装
rpm -qa | grep gcc
gcc-4.4.7-11.el6.x86_64
libgcc-4.4.7-11.el6.x86_64
gcc-c++-4.4.7-11.el6.x86_64
yumsearchLibtool
yuminstalllibtool-ltdl-devel.x86_64
yumsearchlibunistring
yuminstalllibunistring-devel.x86_64
yumsearchlibffi
yuminstalllibffi-devel.x86_64
yumsearchgc

sudo mkdir /usr/local/guile-2.2.4
sudo ./configure --prefix=/usr/local/guile-2.2.4
cd ..

安装libtool
sudo apt install libltdl-dev
下面的跳过
wget http://mirrors.kernel.org/gnu/libtool/libtool-2.4.6.tar.gz \ 
&& tar xzvf libtool-2.4.6.tar.gz \ 
&& cd libtool-2.4.6 \ 
&& sudo ./configure --prefix=/usr/local/libtool-2.4.6
sudo make -j 12 && sudo make install

继续安装guile-2.2.4
cd ../guile-2.2.4/
sudo ./configure --prefix=/usr/local/guile-2.2.4

apt-cache search libgmp
sudo apt install libgmp-dev
apt-cache search libunistring
sudo apt install libunistring-dev
sudo apt install pkg-config
sudo apt install libffi-dev

To build a working version of the collector, you will need to do something like the following, where D is the absolute path to an installation directory:

cd /home/love/gmp-mpfr-mpc
git clone git://github.com/ivmai/libatomic_ops.git
git clone git://github.com/ivmai/bdwgc.git
ln -s  /home/love/gmp-mpfr-mpc/libatomic_ops /home/love/gmp-mpfr-mpc/bdwgc/libatomic_ops
cd bdwgc

sudo apt install dh-autoreconf

autoreconf -vif
sudo automake --add-missing
./configure
sudo make -j 12
sudo make install

安装bdw-gc
sudo apt install libgc-dev
sudo apt install libreadline-dev
sudo apt install python-dev
sudo apt install python3-dev



sudo find / -name Python.h
/usr/include/python3.6m/Python.h
/usr/include/python2.7/Python.h
sudo cp -R  /usr/include/python3.6m/Python.h /usr/include/

sudo cp -R  /usr/include/python3.6m/patchlevel.h /usr/include/
sudo cp -R  /usr/include/python3.6m/* /usr/include/



wget -c http://www.lua.org/ftp/lua-5.3.5.tar.gz
tar zxf lua-5.3.5.tar.gz
cd lua-5.3.5
make linux test
sudo make install


wget -c http://sourceforge.net/projects/libcord/files/OldFiles/libcord-0.7.tar.bz2/download
mv download libcord-0.7.tar.bz2
tar -jxvf libcord-0.7.tar.bz2
cd libcord-0.7/
sudo make -j 4
sudo make install




cd ~
git clone git://github.com/ivmai/libatomic_ops.git
git clone git://github.com/ivmai/bdwgc.git
ln -s  ~/libatomic_ops ~/bdwgc/libatomic_ops
cd bdwgc
autoreconf -vif
automake --add-missing
sudo ./configure --prefix=/usr/local/bdwgc
sudo make -j 4
sudo make install



git clone https://github.com/ivmai/bdwgc.git
git clone git://github.com/ivmai/bdwgc.git
cd bdwgc
git clone git://github.com/ivmai/libatomic_ops.git
./autogen.sh
sudo ./configure --prefix=/usr/local/bdwgc
sudo make -j 4
sudo make check



cd libatomic_ops/
./autogen.sh
sudo ./configure --prefix=/usr/local/libatomic_ops
sudo make -j 4
sudo make install


wget -c https://github.com/ivmai/bdwgc/releases/download/v8.0.4/gc-8.0.4.tar.gz
tar -xvf gc-8.0.4.tar.gz
cd gc-8.0.4
sudo ./configure --prefix=/usr/local/gc-8.0.4
sudo make -j 4
sudo make install





继续安装guile-2.2.4
cd ../guile-2.2.4/
sudo ./configure --prefix=/usr/local/guile-2.2.4
sudo make -j 12
sudo make install


sudo wget https://mirrors.ustc.edu.cn/gnu/gcc/gcc-9.1.0/gcc-9.1.0.tar.gz
tar -xvf gcc-9.1.0.tar.gz
cd gcc-9.1.0

mkdir temp
cd temp
sudo ../configure --disable-multilib --enable-languages=c,c++ --with-gmp=/usr/local/gmp-6.1.2 --with-mpfr=/usr/local/mpfr-4.0.2 --with-mpc=/usr/local/mpc-1.1.0 
# 如果报错 请使用 ../configure --disable-multilib --enable-languages=c,c++
sudo make -j 12
sudo make install



wget命令说明
启动参数编辑
这一类参数主要提供软件的一些基本信息。
-V,--version 显示软件版本号然后退出；
-h,--help显示软件帮助信息；
-e,--execute=COMMAND 执行一个 “.wgetrc”命令
以上每一个功能有长短两个参数，长短功能一样，都可以使用。需要注意的是，这里的-e参数是执行一个.wgettrc的命令，.wgettrc命令其实是一个参数列表，直接将软件需要的参数写在一起就可以了。
文件参数编辑
这类参数定义软件log文件的输出方式等。
-o,--output-file=FILE 将软件输出信息保存到文件；
-a,--append-output=FILE将软件输出信息追加到文件；
-d,--debug显示输出信息；
-q,--quiet 不显示输出信息；
-i,--input-file=FILE 从文件中取得URL；
例1：下载首页并且显示下载信息
wget -d
例2：下载首页并且不显示任何信息
wget -q
例3：下载filelist.txt中所包含的链接的所有文件
wget -i filelist.txt
wget -np -m -l 5 不下载本站所链接的其它站点内容，5级目录结构
下载参数编辑
下载参数定义下载重复次数、保存文件名等。
-t,--tries=NUMBER 是否下载次数（0表示无穷次）
-O --output-document=FILE 指定下载目录和文件名
-nc, --no-clobber 不要覆盖已经存在的文件
-N,--timestamping只下载比本地新的文件
-T,--timeout=SECONDS 设置超时时间
-Y,--proxy=on/off 关闭代理
例：下载的首页并将下载过程中的的输入信息保存到test.htm文件中
wget -Otest.html
目录参数
目录参数主要设置下载文件保存目录与原来文件（服务器文件）的目录对应关系；
-nd --no-directories 不建立目录
-x,--force-directories 强制建立目录
可能我们对这里的目录还不是很了解，我们来看一个举例
例：下载的首页，并且保持网站结构
wget -x
HTTP参数
HTTP参数设置一些与HTTP下载有关的属性。
--http-user=USER设置HTTP用户
--http-passwd=PASS设置HTTP密码
--proxy-user=USER设置代理用户
--proxy-passwd=PASS设置代理密码
以上参数主要设置HTTP和代理的用户、密码；
递归参数设置
在下载一个网站或者网站的一个目录的时候，我们需要知道的下载的层次，这些参数就可以设置。
-r,--recursive 下载整个网站、目录（小心使用）
-l,--level=NUMBER 下载层次
例：下载整个网站
wget -r
拒绝选项参数
下载一个网站的时候，为了尽量快，有些文件可以选择下载，比如图片和声音，在这里可以设置。
-A,--accept=LIST 可以接受的文件类型
-R,--reject=LIST拒绝接受的文件类型
-D,--domains=LIST可以接受的域名,用逗号分隔
--exclude-domains=LIST拒绝的域名,用逗号分隔
-L,--relative 下载关联链接
--follow-ftp 只下载FTP链接
-H,--span-hosts 可以下载外面的主机
-I,--include-directories=LIST允许的目录
-X,--exclude-directories=LIST 拒绝的目录


今天操作远端机器的时候发现少一个安装包， 需要传到对方的机器上，还能使用通过的老办法，直接SSH连上去了，发现传的很慢， 只有40K的样子， 看时间还需要二个多小时就有点受不了了。想想有一台FTP服务器上有这个文件，可以直接从FTP服务器上下载不就得了。本想电话指导着操作，但想到对面的操作能力，不禁心里又打起鼓来。



     使用google搜了一下，找到了wget  命令。 格式如下：
 wget    --ftp-user=xiaoxin --ftp-password=54321   -r ftp://10.10.10.10/tool/smc20


  而后就开始下载了，很快有300K ，只有了几分钟就下载完了。下载安装完成。
  以下为WGET常用的参数和命令。
wget  ftp://xiaoxin:123456@10.10.17.193:9999/办处/郑州/cmdl32.exe


  使用wget  命令直接下载cmdl32.exe文件， 指定用户名和密码为xiaoxin和123456
wget    ftp://xiaoxin:123456@10.10.17.193:9999/办处/郑州/工作报表/*


   使用wget命令下载ftp工作报表目录下的所有文件和目录，并下载到当前目录下。
wget -r  ftp://xiaoxin:123456@10.10.17.193:9999/办处/郑州/工作报表/


    参数  -r的做用是下些目录， 作用与上面的命令类似， 但不同之处在于直接使用 -r会在当前止录下面生成以目标IP地址命名的文件夹。 还有，使用 -r 会下载指定目录下的所有文件，包括一些外链文件都会下载，所以可以配置  -l  参数使用。
wget  -r  -c  ftp://xiaoxin:123456@10.10.17.193:9999/办处/郑州/工作报表/ 

    -c  表示使用断点续传功能。在网络状况不佳的情况下很实用。
    wget  -i  down.txt 
    直接使用down.txt中指定的URL时行下载，可以批量下载不同的文件，很方便，不用人一直参与， 多以以下形式出现

     wget  -t  0  -w  31   -i down.txt     表示  -T  为重试次数， 0表示一直重试   -W  表示为失败时等待时长。

    down.txt  文件内容应是一个完整的URL 如下图所示
   ftp://xiaoxin:1@10.10.17.193:9999/办事处/郑州/工作报表/xx.doc
   ftp://xiaoxin:1@10.10.17.193:9999/办事处/郑州/工作报表/xy.doc
    wget  -i down.txt  -o down.log  


   下载down.txt 中指定的URL进行下载，并将下载提示转存到down.log文件中.
      wget  -r -nd  -A.doc  ftp://xiaoxin:1@10.10.17.193:9999




git clone https://github.com/NVIDIA/jetson-gpio.git
sudo python3 setup.py install



第 1 步：安装 CUDA
axel -n 10 https://developer.download.nvidia.cn/compute/cuda/10.1/secure/Prod/local_installers/cuda_10.1.168_418.67_linux_ppc64le.run?JEs7mrM7r_iHieZTpVy4Zft121rra2VdxY1ES4VyLXFcao8hxp_85D40AFbEXWk0Dwt_FGOdkxEx66lBMj0QpE4aHeVTOEYsabjjWNybMcCU2Xo-UbiPGrJAMm3C1iUlRLFRkYtwczeTxt0w7EYprgQTPq6RQq0g9zPs5xlMXy7QCNO69yE7TH7MIfonS8zTDs0Y7g

git clone https://github.com/NVIDIA/cuda-gdb.git



第 2 步：安装 cuDNN
git clone https://github.com/NVIDIA/torch-cudnn.git



第 4 步：安装 NCCL
git clone https://github.com/NVIDIA/nccl.git


第 5 步：安装 Caffe
git clone https://github.com/NVIDIA/caffe.git


git clone git://git.drogon.net/wiringPi

















# 安装chez-scheme
cd ~
wget https://codeload.github.com/cisco/ChezScheme/zip/master
mv master chez-scheme.zip

# 安装依赖
sudo apt install unzip
sudo apt install zip
sudo apt install uuid-dev
sudo apt install libncurses5-dev
sudo apt install libx11-dev

# 开始安装
unzip chez-scheme.zip
cd ChezScheme-master/
sudo ./configure
sudo make -j 8
sudo make install
# 安装chez-scheme完成回到用户目录
cd ~

# 安装common-lisp开发环境完成
sudo apt install m4
# 安装ccl lisp
wget https://github.com/Clozure/ccl/releases/download/v1.12-dev.1/linuxarm.tar.gz
mkdir ccl-1.2
cd ccl-1.2/
cp ../linuxarm.tar.gz ./
tar -zxvf linuxarm.tar.gz
rm linuxarm.tar.gz
cd ../

wget -c https://github.com/Clozure/ccl/releases/download/v1.11.5/ccl-1.11.5-linuxarm.tar.gz
tar -zxvf ccl-1.11.5-linuxarm.tar.gz




# 下载源码
wget https://codeload.github.com/Clozure/ccl/zip/master
mv master ccl-lisp.zip
unzip ccl-lisp.zip
cd ccl-master/
cp ../ccl/armcl.image ./
cp ../ccl/armcl ./
cp -rf ../ccl/arm-headers/ ./
cd lisp-kernel/linuxarm/
make
cd ../../
./armcl
(ccl:rebuild-ccl :full t)
(quit)
./armcl
(ccl:rebuild-ccl :full t)
(quit)
./armcl
(ccl:rebuild-ccl :full t)




lisp各版本源码下载

scheme
git clone https://github.com/cisco/ChezScheme.git

ccl lisp
git clone https://github.com/Clozure/ccl.git

sbcl
git clone https://git.code.sf.net/p/sbcl/sbcl
git clone git://git.code.sf.net/p/sbcl/sbcl.git

可移植的路径名库
git clone https://github.com/edicl/cl-fad.git

正则表达式库
git clone https://github.com/edicl/cl-ppcre.git

Common Lisp的可移植Unicode库
git clone https://github.com/edicl/cl-unicode.git

on lisp
git clone https://github.com/xcv58/onlisp-cn.git


https://github.com/binghe/pcl-cn.git
https://github.com/binghe/informatica-public.git
https://github.com/binghe/HOL.git
https://github.com/binghe/acrobat-actions.git
https://github.com/binghe/cl-net-snmp.git
https://github.com/usocket/usocket.git
https://github.com/binghe/kamasutra-cn.git

https://github.com/dita-ot/dita-ot.git




